{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pythonmag/mag\r\n",
      "Building wheels for collected packages: mag\r\n",
      "  Building wheel for mag (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mag: filename=mag-0.1-cp36-none-any.whl size=10709 sha256=cbaf6291b76010a352be1815fdc111e3f7b65f079c8e91e4efd4ae3ba722fe8a\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jqrxsgfx/wheels/32/ac/43/551a60b3d99206fa44ce7cfd6669c52ab2bfea3b5bf7d8ae08\r\n",
      "Successfully built mag\r\n",
      "Installing collected packages: mag\r\n",
      "Successfully installed mag-0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/pythonmag/mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../input/sacremoses/sacremoses-master/ > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-11 12:43:11.966475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:10<00:00,  5.60it/s]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:10<00:00,  5.85it/s]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.20it/s]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.25it/s]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.23it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python /kaggle/input/old-bert-code/predict_test.py --model_dir /kaggle/input/stackx-80-aux-ep-3 --sub_file old_base.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_EXPERIMENT_DIR = \"2-4-roberta-base-saved-5-head_tail-roberta-stackx-base-v2-pl1kksample20k-1e-05-210-260-500-26-roberta-200\"\n",
    "!mkdir $ROBERTA_EXPERIMENT_DIR\n",
    "!ln -s /kaggle/input/roberta-stackx-base-pl20k/checkpoints $ROBERTA_EXPERIMENT_DIR/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_CONFIG = {\n",
    "    \"_seed\": 42,\n",
    "    \"batch_accumulation\": 2,\n",
    "    \"batch_size\": 4,\n",
    "    \"bert_model\": \"roberta-base-saved\",\n",
    "    \"folds\": 5,\n",
    "    \"head_tail\": True,\n",
    "    \"label\": \"roberta-stackx-base-v2-pl1kksample20k\",\n",
    "    \"lr\": 1e-05,\n",
    "    \"max_answer_length\": 210,\n",
    "    \"max_question_length\": 260,\n",
    "    \"max_sequence_length\": 500,\n",
    "    \"max_title_length\": 26,\n",
    "    \"model_type\": \"roberta\",\n",
    "    \"warmup\": 200\n",
    "}\n",
    "with open(os.path.join(ROBERTA_EXPERIMENT_DIR, \"config.json\"), \"w\") as fp:\n",
    "    json.dump(ROBERTA_CONFIG, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo kek > $ROBERTA_EXPERIMENT_DIR/command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-11 12:44:54.129298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n",
      "\r\n",
      "Fold: 0\r\n",
      "\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:13<00:00,  8.71it/s]\r\n",
      "\r\n",
      "Fold: 1\r\n",
      "\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:11<00:00,  9.92it/s]\r\n",
      "\r\n",
      "Fold: 2\r\n",
      "\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:12<00:00,  9.43it/s]\r\n",
      "\r\n",
      "Fold: 3\r\n",
      "\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:11<00:00,  9.96it/s]\r\n",
      "\r\n",
      "Fold: 4\r\n",
      "\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:12<00:00,  9.85it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../input/roberta-base-code/infer.py --experiment $ROBERTA_EXPERIMENT_DIR --checkpoint=best_model.pth --bert_model=/kaggle/input/roberta-base-model --dataframe=/kaggle/input/google-quest-challenge/test.csv --output_dir=roberta-base-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-11 12:46:37.442327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n",
      "Initial arguments Namespace(batch_accumulation=4, batch_size=8, bert_model='/kaggle/input/bert-base-pretrained/stackx-base-cased/', data_path='/kaggle/input/google-quest-challenge/', epochs=5, folds=5, head_tail=True, label='qa', leak_free_pseudo=False, lr=2e-05, max_answer_length=210, max_question_length=260, max_sequence_length=500, max_title_length=26, num_classes=30, pseudo_file=None, seed=42, split_pseudo=False, sub_file='bert_base.csv', warmup=200, workers=8)\r\n",
      "Preparing dataset: 100%|██████████████████████| 476/476 [00:05<00:00, 84.76it/s]\r\n",
      "Fold 0\r\n",
      "Test: 100%|█████████████████████████████████████| 60/60 [00:09<00:00,  6.45it/s]\r\n",
      "Fold 1\r\n",
      "Test: 100%|█████████████████████████████████████| 60/60 [00:08<00:00,  6.75it/s]\r\n",
      "Fold 2\r\n",
      "Test: 100%|█████████████████████████████████████| 60/60 [00:08<00:00,  6.74it/s]\r\n",
      "Fold 3\r\n",
      "Test: 100%|█████████████████████████████████████| 60/60 [00:08<00:00,  6.73it/s]\r\n",
      "Fold 4\r\n",
      "Test: 100%|█████████████████████████████████████| 60/60 [00:08<00:00,  6.74it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../input/bert-base-random-code/run.py --sub_file=bert_base.csv --data_path=/kaggle/input/google-quest-challenge/ --max_sequence_length=500 --max_title_length=26 --max_question_length=260 --max_answer_length=210 --batch_size=8 --bert_model=/kaggle/input/bert-base-pretrained/stackx-base-cased/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/sacrebleu/sacreBLEU-master\r\n",
      "Requirement already satisfied: typing in /opt/conda/lib/python3.6/site-packages (from sacrebleu==1.3.7) (3.6.4)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.6/site-packages (from sacrebleu==1.3.7) (1.5.2)\r\n",
      "Building wheels for collected packages: sacrebleu\r\n",
      "  Building wheel for sacrebleu (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacrebleu: filename=sacrebleu-1.3.7-cp36-none-any.whl size=26696 sha256=59b74cdac966f7da11f8b98201ec7e2a71bbaa751fa369d42efed23d842e7909\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/fb/1c/3d/2486ca75b6b615aee93a30e81a54798cae785aaf6e084047f3\r\n",
      "Successfully built sacrebleu\r\n",
      "Installing collected packages: sacrebleu\r\n",
      "Successfully installed sacrebleu-1.3.7\r\n",
      "Processing /kaggle/input/fairseq-hacked/fairseq\r\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (1.13.2)\r\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (0.29.14)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (1.18.1)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (2020.1.8)\r\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (1.3.7)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (1.4.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from fairseq==0.9.0) (4.41.1)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi->fairseq==0.9.0) (2.19)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.6/site-packages (from sacrebleu->fairseq==0.9.0) (1.5.2)\r\n",
      "Requirement already satisfied: typing in /opt/conda/lib/python3.6/site-packages (from sacrebleu->fairseq==0.9.0) (3.6.4)\r\n",
      "Building wheels for collected packages: fairseq\r\n",
      "  Building wheel for fairseq (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2007733 sha256=86f29e458b917edb310a07c62d5d8dba7e92f923fa29ce41d38474fc0150a1af\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hbo5t798/wheels/c0/0f/f7/ef1f9de66f9e7df8e9c55ecc83d69c8af4b45d1204cc04008b\r\n",
      "Successfully built fairseq\r\n",
      "Installing collected packages: fairseq\r\n",
      "Successfully installed fairseq-0.9.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/sacrebleu/sacreBLEU-master/\n",
    "!pip install /kaggle/input/fairseq-hacked/fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial arguments Namespace(batch_accumulation=4, batch_size=4, bert_model='bart.large', data_path='/kaggle/input/google-quest-challenge/', epochs=5, folds=5, head_tail=True, label='qa', leak_free_pseudo=False, lr=2e-05, max_answer_length=210, max_question_length=260, max_sequence_length=500, max_title_length=26, num_classes=30, pseudo_file=None, seed=42, split_pseudo=False, sub_file='bart_base.csv', warmup=200, workers=8)\r\n",
      "| dictionary: 50264 types\r\n",
      "Almost done\r\n",
      "Preparing dataset: 100%|██████████████████████| 476/476 [00:06<00:00, 77.67it/s]\r\n",
      "| dictionary: 50264 types\r\n",
      "Almost done\r\n",
      "Fold 0\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:37<00:00,  3.19it/s]\r\n",
      "Fold 1\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:37<00:00,  3.21it/s]\r\n",
      "Fold 2\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:37<00:00,  3.21it/s]\r\n",
      "Fold 3\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:37<00:00,  3.22it/s]\r\n",
      "Fold 4\r\n",
      "Test: 100%|███████████████████████████████████| 119/119 [00:37<00:00,  3.21it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python ../input/bart-code/run.py --sub_file=bart_base.csv --data_path=/kaggle/input/google-quest-challenge/ --max_sequence_length=500 --max_title_length=26 --max_question_length=260 --max_answer_length=210 --batch_size=4 --bert_model=bart.large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['question_asker_intent_understanding',\n",
    "   'question_body_critical', 'question_conversational',\n",
    "   'question_expect_short_answer', 'question_fact_seeking',\n",
    "   'question_has_commonly_accepted_answer',\n",
    "   'question_interestingness_others', 'question_interestingness_self',\n",
    "   'question_multi_intent', 'question_not_really_a_question',\n",
    "   'question_opinion_seeking', 'question_type_choice',\n",
    "   'question_type_compare', 'question_type_consequence',\n",
    "   'question_type_definition', 'question_type_entity',\n",
    "   'question_type_instructions', 'question_type_procedure',\n",
    "   'question_type_reason_explanation', 'question_type_spelling',\n",
    "   'question_well_written', 'answer_helpful',\n",
    "   'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
    "   'answer_satisfaction', 'answer_type_instructions',\n",
    "   'answer_type_procedure', 'answer_type_reason_explanation',\n",
    "   'answer_well_written']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_single(target, ref):\n",
    "    \"\"\"\n",
    "    The idea here is to make the distribution of a particular predicted column\n",
    "    to match the correspoding distribution of the corresponding column in the\n",
    "    training dataset (called ref here)\n",
    "    \"\"\"\n",
    "    \n",
    "    ids = np.argsort(target)\n",
    "    counts = sorted(Counter(ref).items(), key=lambda s: s[0])\n",
    "    scores = np.zeros_like(target)\n",
    "    \n",
    "    last_pos = 0\n",
    "    v = 0\n",
    "    \n",
    "    for value, count in counts:\n",
    "        next_pos = last_pos + int(round(count / len(ref) * len(target)))\n",
    "        if next_pos == last_pos:\n",
    "            next_pos += 1\n",
    "\n",
    "        cond = ids[last_pos:next_pos]\n",
    "        scores[cond] = v\n",
    "        last_pos = next_pos\n",
    "        v += 1\n",
    "        \n",
    "    return scores / scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_prediction(prediction, actual):\n",
    "    \n",
    "    postprocessed = prediction.copy()\n",
    "    \n",
    "    for col in target_columns:\n",
    "        scores = postprocess_single(prediction[col].values, actual[col].values)\n",
    "        # Those are columns where our postprocessing gave substantial improvement.\n",
    "        # It also helped for some others, but we didn't include them as the gain was\n",
    "        # very marginal (less than 0.01)\n",
    "        if col in (\n",
    "            \"question_conversational\",\n",
    "            \"question_type_compare\",\n",
    "            \"question_type_definition\",\n",
    "            \"question_type_entity\",\n",
    "            \"question_has_commonly_accepted_answer\",\n",
    "            \"question_type_consequence\",\n",
    "            \"question_type_spelling\"\n",
    "        ):\n",
    "            postprocessed[col] = scores\n",
    "    \n",
    "    return postprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_base_dfs = [pd.read_csv(os.path.join(\"roberta-base-output\", \"fold-{}.csv\".format(fold))) for fold in range(5)]\n",
    "roberta_pred_df = roberta_base_dfs[0].copy()\n",
    "for col in target_columns:\n",
    "    roberta_pred_df[col] = np.mean([df[col] for df in roberta_base_dfs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_pred_df = pd.read_csv(\"bert_base.csv\")\n",
    "bart_base_pred_df = pd.read_csv(\"bart_base.csv\")\n",
    "bert_old_base_pred_df = pd.read_csv(\"old_base.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/google-quest-challenge/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_df = roberta_pred_df.copy()\n",
    "\n",
    "for col in target_columns:\n",
    "    blended_df[col] = (\n",
    "        bert_old_base_pred_df[col] * 0.1 +\n",
    "        bert_base_pred_df[col] * 0.2 + \n",
    "        roberta_pred_df[col] * 0.1 + \n",
    "        bart_base_pred_df[col] * 0.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed = postprocess_prediction(blended_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in target_columns:\n",
    "    # scale to 0-1 interval\n",
    "    v = postprocessed[col].values\n",
    "    postprocessed[col] = (v - v.min()) / (v.max() - v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
